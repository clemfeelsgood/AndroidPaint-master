{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57cUBU_kW8YI"
      },
      "source": [
        "<div id=\"colab_button\\\">\n",
        "    <h1>LaVague: Quick-tour guide</h1>\n",
        "    <a target=\"_blank\\\" href=\"https://colab.research.google.com/github/lavague-ai/lavague/blob/main/docs/docs/get-started/quick-tour.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "    </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz-THRuD5FnO"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "LaVague is an open-source framework allowing users to leverage AI to turn natural language instructions into executable code to automate UI actions, such as filling in a form, etc.\n",
        "\n",
        "In this quick tour, we are going to show you how you can quickly get started with LaVague to:\n",
        "- Launch an interactive Gradio where you can test running example actions on a webpage\n",
        "- Generate the Python code needed to perform an action on the webpage of your choice based on natural language instructions\n",
        "\n",
        "> Pre-requisites: Note, if you are running the notebook locally, you will need Python (tested on python>=3.8) and pip installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1shA6wK05FnP"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zguQ2OS65FnQ"
      },
      "source": [
        "### Installing driver for Selenium\n",
        "\n",
        "By default, LaVague generates code that leverages [Selenium](https://www.selenium.dev/) to perform user interface actions.\n",
        "\n",
        "Selenium requires a driver to be installed to interface with the chosen browser (Chrome, Firefox, etc.)\n",
        "\n",
        "We therefore first need to download the Chrome driver.\n",
        "\n",
        "⚠️ For instructions on how to install a driver on a different OS, [see the Selenium documentation](https://selenium-python.readthedocs.io/installation.html#drivers)\n",
        "\n",
        "> Note that while we use Selenium for this example. We hope to integrate different automation tools such as Playwright at a later date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtUS9ehU5FnQ"
      },
      "source": [
        "First, we need to make sure we have the following packages installed on our system.\n",
        "\n",
        "> Note, if you are missing any of these packages, you will need to run `sudo apt update` first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "22ZU86wd5FnR",
        "outputId": "f0a2a481-7f46-44d0-a505-195841cb3675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libgcc-s1' instead of 'libgcc1'\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libasound2 set to manually installed.\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk-bridge2.0-0 set to manually installed.\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatk1.0-0 set to manually installed.\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo2 set to manually installed.\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libfontconfig1 set to manually installed.\n",
            "libnspr4 is already the newest version (2:4.32-3build1).\n",
            "libnspr4 set to manually installed.\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb1 set to manually installed.\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxcomposite1 set to manually installed.\n",
            "libxcursor1 is already the newest version (1:1.2.0-2build4).\n",
            "libxcursor1 set to manually installed.\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxdamage1 set to manually installed.\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxfixes3 set to manually installed.\n",
            "libxi6 is already the newest version (2:1.8-1build1).\n",
            "libxi6 set to manually installed.\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "libxrandr2 set to manually installed.\n",
            "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
            "libxrender1 set to manually installed.\n",
            "libxss1 is already the newest version (1:1.2.3-1build2).\n",
            "libxss1 set to manually installed.\n",
            "lsb-release is already the newest version (11.1.0ubuntu4).\n",
            "lsb-release set to manually installed.\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "libc6 is already the newest version (2.35-0ubuntu3.6).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.8).\n",
            "libcups2 set to manually installed.\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdbus-1-3 set to manually installed.\n",
            "libexpat1 is already the newest version (2.4.7-1ubuntu0.3).\n",
            "libexpat1 set to manually installed.\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.2).\n",
            "libgbm1 set to manually installed.\n",
            "libgcc-s1 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.2).\n",
            "libglib2.0-0 set to manually installed.\n",
            "libgtk-3-0 is already the newest version (3.24.33-1ubuntu2).\n",
            "libgtk-3-0 set to manually installed.\n",
            "libnss3 is already the newest version (2:3.68.2-0ubuntu1.2).\n",
            "libnss3 set to manually installed.\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpango-1.0-0 set to manually installed.\n",
            "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpangocairo-1.0-0 set to manually installed.\n",
            "libstdc++6 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-6 set to manually installed.\n",
            "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-xcb1 set to manually installed.\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "xdg-utils is already the newest version (1.1.3-4.1ubuntu3~22.04.1).\n",
            "xdg-utils set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libdbusmenu-glib4 libdbusmenu-gtk3-4\n",
            "Suggested packages:\n",
            "  indicator-application\n",
            "The following NEW packages will be installed:\n",
            "  libappindicator3-1 libdbusmenu-glib4 libdbusmenu-gtk3-4 libxtst6\n",
            "0 upgraded, 4 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 113 kB of archives.\n",
            "After this operation, 432 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdbusmenu-glib4 amd64 16.04.1+18.10.20180917-0ubuntu8 [45.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdbusmenu-gtk3-4 amd64 16.04.1+18.10.20180917-0ubuntu8 [31.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libappindicator3-1 amd64 12.10.1+20.10.20200706.1-0ubuntu1 [23.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Fetched 113 kB in 1s (89.7 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libdbusmenu-glib4:amd64.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../libdbusmenu-glib4_16.04.1+18.10.20180917-0ubuntu8_amd64.deb ...\n",
            "Unpacking libdbusmenu-glib4:amd64 (16.04.1+18.10.20180917-0ubuntu8) ...\n",
            "Selecting previously unselected package libdbusmenu-gtk3-4:amd64.\n",
            "Preparing to unpack .../libdbusmenu-gtk3-4_16.04.1+18.10.20180917-0ubuntu8_amd64.deb ...\n",
            "Unpacking libdbusmenu-gtk3-4:amd64 (16.04.1+18.10.20180917-0ubuntu8) ...\n",
            "Selecting previously unselected package libappindicator3-1.\n",
            "Preparing to unpack .../libappindicator3-1_12.10.1+20.10.20200706.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libappindicator3-1 (12.10.1+20.10.20200706.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libdbusmenu-glib4:amd64 (16.04.1+18.10.20180917-0ubuntu8) ...\n",
            "Setting up libdbusmenu-gtk3-4:amd64 (16.04.1+18.10.20180917-0ubuntu8) ...\n",
            "Setting up libappindicator3-1 (12.10.1+20.10.20200706.1-0ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# If you are missing any apt packages uncomment and run this command first:\n",
        "# !sudo apt update\n",
        "\n",
        "!sudo apt install -y ca-certificates fonts-liberation unzip \\\n",
        "libappindicator3-1 libasound2 libatk-bridge2.0-0 libatk1.0-0 libc6 \\\n",
        "libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgbm1 \\\n",
        "libgcc1 libglib2.0-0 libgtk-3-0 libnspr4 libnss3 libpango-1.0-0 \\\n",
        "libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 \\\n",
        "libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 \\\n",
        "libxrandr2 libxrender1 libxss1 libxtst6 lsb-release wget xdg-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPgI2NEl5FnS"
      },
      "source": [
        "Now we can install the necessary Chrome webdriver files for Linux."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_OkxxXPA5FnT",
        "outputId": "8bdfa7af-580e-44b1-86e0-98735fcf95bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-25 14:15:15--  https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chrome-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.207, 142.251.10.207, 142.251.12.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149157879 (142M) [application/zip]\n",
            "Saving to: ‘chrome-linux64.zip’\n",
            "\n",
            "chrome-linux64.zip  100%[===================>] 142.25M  23.7MB/s    in 7.1s    \n",
            "\n",
            "2024-03-25 14:15:23 (20.0 MB/s) - ‘chrome-linux64.zip’ saved [149157879/149157879]\n",
            "\n",
            "--2024-03-25 14:15:23--  https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chromedriver-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.207, 142.251.10.207, 142.251.12.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8597995 (8.2M) [application/zip]\n",
            "Saving to: ‘chromedriver-linux64.zip’\n",
            "\n",
            "chromedriver-linux6 100%[===================>]   8.20M  5.75MB/s    in 1.4s    \n",
            "\n",
            "2024-03-25 14:15:24 (5.75 MB/s) - ‘chromedriver-linux64.zip’ saved [8597995/8597995]\n",
            "\n",
            "Archive:  chrome-linux64.zip\n",
            "  inflating: chrome-linux64/ABOUT    \n",
            "  inflating: chrome-linux64/MEIPreload/manifest.json  \n",
            "  inflating: chrome-linux64/MEIPreload/preloaded_data.pb  \n",
            "  inflating: chrome-linux64/chrome   \n",
            "  inflating: chrome-linux64/chrome-wrapper  \n",
            "  inflating: chrome-linux64/chrome_100_percent.pak  \n",
            "  inflating: chrome-linux64/chrome_200_percent.pak  \n",
            "  inflating: chrome-linux64/chrome_crashpad_handler  \n",
            "  inflating: chrome-linux64/chrome_sandbox  \n",
            "  inflating: chrome-linux64/icudtl.dat  \n",
            "  inflating: chrome-linux64/libEGL.so  \n",
            "  inflating: chrome-linux64/libGLESv2.so  \n",
            "  inflating: chrome-linux64/libvk_swiftshader.so  \n",
            "  inflating: chrome-linux64/libvulkan.so.1  \n",
            " extracting: chrome-linux64/product_logo_48.png  \n",
            "  inflating: chrome-linux64/resources.pak  \n",
            "  inflating: chrome-linux64/v8_context_snapshot.bin  \n",
            "  inflating: chrome-linux64/vk_swiftshader_icd.json  \n",
            "  inflating: chrome-linux64/xdg-mime  \n",
            "  inflating: chrome-linux64/xdg-settings  \n",
            "   creating: chrome-linux64/locales/\n",
            "  inflating: chrome-linux64/locales/af.pak.info  \n",
            "  inflating: chrome-linux64/locales/ja.pak  \n",
            "  inflating: chrome-linux64/locales/fil.pak  \n",
            "  inflating: chrome-linux64/locales/ca.pak.info  \n",
            "  inflating: chrome-linux64/locales/es.pak.info  \n",
            "  inflating: chrome-linux64/locales/th.pak  \n",
            "  inflating: chrome-linux64/locales/en-GB.pak.info  \n",
            "  inflating: chrome-linux64/locales/ro.pak  \n",
            "  inflating: chrome-linux64/locales/fil.pak.info  \n",
            "  inflating: chrome-linux64/locales/en-US.pak.info  \n",
            "  inflating: chrome-linux64/locales/hi.pak.info  \n",
            "  inflating: chrome-linux64/locales/sw.pak.info  \n",
            "  inflating: chrome-linux64/locales/lv.pak.info  \n",
            "  inflating: chrome-linux64/locales/sw.pak  \n",
            "  inflating: chrome-linux64/locales/uk.pak  \n",
            "  inflating: chrome-linux64/locales/de.pak.info  \n",
            "  inflating: chrome-linux64/locales/sv.pak.info  \n",
            "  inflating: chrome-linux64/locales/et.pak.info  \n",
            "  inflating: chrome-linux64/locales/ko.pak  \n",
            "  inflating: chrome-linux64/locales/zh-CN.pak  \n",
            "  inflating: chrome-linux64/locales/bg.pak  \n",
            "  inflating: chrome-linux64/locales/sl.pak.info  \n",
            "  inflating: chrome-linux64/locales/id.pak.info  \n",
            "  inflating: chrome-linux64/locales/pl.pak.info  \n",
            "  inflating: chrome-linux64/locales/ru.pak.info  \n",
            "  inflating: chrome-linux64/locales/it.pak.info  \n",
            "  inflating: chrome-linux64/locales/ko.pak.info  \n",
            "  inflating: chrome-linux64/locales/mr.pak.info  \n",
            "  inflating: chrome-linux64/locales/mr.pak  \n",
            "  inflating: chrome-linux64/locales/es.pak  \n",
            "  inflating: chrome-linux64/locales/cs.pak.info  \n",
            "  inflating: chrome-linux64/locales/hr.pak.info  \n",
            "  inflating: chrome-linux64/locales/cs.pak  \n",
            "  inflating: chrome-linux64/locales/lt.pak  \n",
            "  inflating: chrome-linux64/locales/ml.pak.info  \n",
            "  inflating: chrome-linux64/locales/te.pak  \n",
            "  inflating: chrome-linux64/locales/ta.pak.info  \n",
            "  inflating: chrome-linux64/locales/ca.pak  \n",
            "  inflating: chrome-linux64/locales/gu.pak  \n",
            "  inflating: chrome-linux64/locales/ar.pak  \n",
            "  inflating: chrome-linux64/locales/ms.pak  \n",
            "  inflating: chrome-linux64/locales/uk.pak.info  \n",
            "  inflating: chrome-linux64/locales/da.pak  \n",
            "  inflating: chrome-linux64/locales/nb.pak.info  \n",
            "  inflating: chrome-linux64/locales/am.pak.info  \n",
            "  inflating: chrome-linux64/locales/ml.pak  \n",
            "  inflating: chrome-linux64/locales/ro.pak.info  \n",
            "  inflating: chrome-linux64/locales/ur.pak.info  \n",
            "  inflating: chrome-linux64/locales/sk.pak  \n",
            "  inflating: chrome-linux64/locales/es-419.pak  \n",
            "  inflating: chrome-linux64/locales/th.pak.info  \n",
            "  inflating: chrome-linux64/locales/en-GB.pak  \n",
            "  inflating: chrome-linux64/locales/he.pak  \n",
            "  inflating: chrome-linux64/locales/ta.pak  \n",
            "  inflating: chrome-linux64/locales/hu.pak.info  \n",
            "  inflating: chrome-linux64/locales/lt.pak.info  \n",
            "  inflating: chrome-linux64/locales/te.pak.info  \n",
            "  inflating: chrome-linux64/locales/et.pak  \n",
            "  inflating: chrome-linux64/locales/zh-TW.pak.info  \n",
            "  inflating: chrome-linux64/locales/af.pak  \n",
            "  inflating: chrome-linux64/locales/zh-TW.pak  \n",
            "  inflating: chrome-linux64/locales/zh-CN.pak.info  \n",
            "  inflating: chrome-linux64/locales/id.pak  \n",
            "  inflating: chrome-linux64/locales/hi.pak  \n",
            "  inflating: chrome-linux64/locales/ja.pak.info  \n",
            "  inflating: chrome-linux64/locales/kn.pak  \n",
            "  inflating: chrome-linux64/locales/bn.pak  \n",
            "  inflating: chrome-linux64/locales/el.pak  \n",
            "  inflating: chrome-linux64/locales/en-US.pak  \n",
            "  inflating: chrome-linux64/locales/el.pak.info  \n",
            "  inflating: chrome-linux64/locales/sr.pak  \n",
            "  inflating: chrome-linux64/locales/fr.pak  \n",
            "  inflating: chrome-linux64/locales/ar.pak.info  \n",
            "  inflating: chrome-linux64/locales/de.pak  \n",
            "  inflating: chrome-linux64/locales/vi.pak  \n",
            "  inflating: chrome-linux64/locales/pt-BR.pak  \n",
            "  inflating: chrome-linux64/locales/hu.pak  \n",
            "  inflating: chrome-linux64/locales/nl.pak.info  \n",
            "  inflating: chrome-linux64/locales/bg.pak.info  \n",
            "  inflating: chrome-linux64/locales/gu.pak.info  \n",
            "  inflating: chrome-linux64/locales/bn.pak.info  \n",
            "  inflating: chrome-linux64/locales/pt-PT.pak.info  \n",
            "  inflating: chrome-linux64/locales/kn.pak.info  \n",
            "  inflating: chrome-linux64/locales/hr.pak  \n",
            "  inflating: chrome-linux64/locales/fi.pak.info  \n",
            "  inflating: chrome-linux64/locales/pt-PT.pak  \n",
            "  inflating: chrome-linux64/locales/ms.pak.info  \n",
            "  inflating: chrome-linux64/locales/ur.pak  \n",
            "  inflating: chrome-linux64/locales/it.pak  \n",
            "  inflating: chrome-linux64/locales/fr.pak.info  \n",
            "  inflating: chrome-linux64/locales/pl.pak  \n",
            "  inflating: chrome-linux64/locales/es-419.pak.info  \n",
            "  inflating: chrome-linux64/locales/sr.pak.info  \n",
            "  inflating: chrome-linux64/locales/fa.pak.info  \n",
            "  inflating: chrome-linux64/locales/tr.pak  \n",
            "  inflating: chrome-linux64/locales/pt-BR.pak.info  \n",
            "  inflating: chrome-linux64/locales/fa.pak  \n",
            "  inflating: chrome-linux64/locales/vi.pak.info  \n",
            "  inflating: chrome-linux64/locales/he.pak.info  \n",
            "  inflating: chrome-linux64/locales/nb.pak  \n",
            "  inflating: chrome-linux64/locales/lv.pak  \n",
            "  inflating: chrome-linux64/locales/nl.pak  \n",
            "  inflating: chrome-linux64/locales/fi.pak  \n",
            "  inflating: chrome-linux64/locales/ru.pak  \n",
            "  inflating: chrome-linux64/locales/da.pak.info  \n",
            "  inflating: chrome-linux64/locales/tr.pak.info  \n",
            "  inflating: chrome-linux64/locales/sk.pak.info  \n",
            "  inflating: chrome-linux64/locales/sl.pak  \n",
            "  inflating: chrome-linux64/locales/am.pak  \n",
            "  inflating: chrome-linux64/locales/sv.pak  \n",
            "   creating: chrome-linux64/resources/\n",
            "   creating: chrome-linux64/resources/inspector_overlay/\n",
            "  inflating: chrome-linux64/resources/inspector_overlay/main.js  \n",
            "  inflating: chrome-linux64/resources/inspector_overlay/inspector_overlay_resources.grd  \n",
            "Archive:  chromedriver-linux64.zip\n",
            "  inflating: chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: chromedriver-linux64/chromedriver  \n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chrome-linux64.zip\n",
        "!wget https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chromedriver-linux64.zip\n",
        "!unzip chrome-linux64.zip\n",
        "!unzip chromedriver-linux64.zip\n",
        "!rm chrome-linux64.zip chromedriver-linux64.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWPU0o6h5FnU"
      },
      "source": [
        "Note that by default, LaVague assumes that the chrome-linux64 and chromedriver-linux64 folders will be available at root - we will therefore move them to the root directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "tbJevbIC5FnU"
      },
      "outputs": [],
      "source": [
        "!mv chrome-linux64/ ~/\n",
        "!mv chromedriver-linux64/ ~/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ4IJQUm5FnU"
      },
      "source": [
        "### Installing LaVague\n",
        "\n",
        "We now need to install LaVague, which contains the `ActionEngine` module dedicated to handling all the key AI operations and the `CommandCenter` module, which orchestrates the whole workflow, as well as the `LaVague CLI` tool.\n",
        "\n",
        "> Note, here we will install LaVague from the latest GitHub commit on `main` to be sure we have the very latest files at this early fast-moving stage of the project. However, we do provide a PyPi package and will move to installing the package via pip once the project is more stable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0P96AjdI5FnU",
        "outputId": "58d03b94-d571-4615-8e39-20778da9ed78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LaVague'...\n",
            "remote: Enumerating objects: 863, done.\u001b[K\n",
            "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 863 (delta 236), reused 154 (delta 154), pack-reused 574\u001b[K\n",
            "Receiving objects: 100% (863/863), 20.44 MiB | 15.63 MiB/s, done.\n",
            "Resolving deltas: 100% (454/454), done.\n",
            "Obtaining file:///content/LaVague\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama-index==0.10.19 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index-0.10.19-py3-none-any.whl (5.6 kB)\n",
            "Collecting llama-index-agent-openai==0.1.5 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli==0.1.9 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_cli-0.1.9-py3-none-any.whl (25 kB)\n",
            "Collecting llama-index-core==0.10.19 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_core-0.10.19-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-azure-openai==0.1.5 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_embeddings_azure_openai-0.1.5-py3-none-any.whl (3.0 kB)\n",
            "Collecting llama-index-embeddings-huggingface==0.1.4 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_embeddings_huggingface-0.1.4-py3-none-any.whl (7.7 kB)\n",
            "Collecting llama-index-embeddings-openai==0.1.6 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud==0.1.4 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl (6.6 kB)\n",
            "Collecting llama-index-legacy==0.9.48 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-azure-openai==0.1.5 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_llms_azure_openai-0.1.5-py3-none-any.whl (4.5 kB)\n",
            "Collecting llama-index-llms-huggingface==0.1.4 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_llms_huggingface-0.1.4-py3-none-any.whl (7.2 kB)\n",
            "Collecting llama-index-llms-openai==0.1.9 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_llms_openai-0.1.9-py3-none-any.whl (10.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai==0.1.4 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai==0.1.4 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Collecting llama-index-question-gen-openai==0.1.3 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file==0.1.9 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_readers_file-0.1.9-py3-none-any.whl (35 kB)\n",
            "Collecting llama-index-readers-llama-parse==0.1.3 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
            "Collecting llama-index-retrievers-bm25==0.1.3 (from lavague==1.0.4.post1)\n",
            "  Downloading llama_index_retrievers_bm25-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting tree-sitter==0.21.0 (from lavague==1.0.4.post1)\n",
            "  Downloading tree_sitter-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (496 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.6/496.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tree-sitter-languages==1.10.2 (from lavague==1.0.4.post1)\n",
            "  Downloading tree_sitter_languages-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (from lavague==1.0.4.post1) (1.6.0)\n",
            "Collecting selenium==4.18.1 (from lavague==1.0.4.post1)\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-search-results==2.4.2 (from lavague==1.0.4.post1)\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv==1.0.1 (from lavague==1.0.4.post1)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting accelerate==0.28.0 (from lavague==1.0.4.post1)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.42.0 (from lavague==1.0.4.post1)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==4.21.0 (from lavague==1.0.4.post1)\n",
            "  Downloading gradio-4.21.0-py3-none-any.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->lavague==1.0.4.post1) (0.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0->lavague==1.0.4.post1) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results==2.4.2->lavague==1.0.4.post1) (2.31.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (4.2.2)\n",
            "Collecting fastapi (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.12.0 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading gradio_client-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (6.3.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (2.6.4)\n",
            "Collecting pydub (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading ruff-0.3.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.21.0->lavague==1.0.4.post1) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (3.9.3)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (2023.6.0)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (3.8.1)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.19->lavague==1.0.4.post1) (4.66.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface==0.1.4->lavague==1.0.4.post1) (4.38.2)\n",
            "Collecting azure-identity<2.0.0,>=1.15.0 (from llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1)\n",
            "  Downloading azure_identity-1.15.0-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.7/164.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file==0.1.9->lavague==1.0.4.post1) (4.12.3)\n",
            "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file==0.1.9->lavague==1.0.4.post1)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file==0.1.9->lavague==1.0.4.post1)\n",
            "  Downloading PyMuPDF-1.24.0-cp310-none-manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file==0.1.9->lavague==1.0.4.post1)\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file==0.1.9->lavague==1.0.4.post1)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse==0.1.3->lavague==1.0.4.post1)\n",
            "  Downloading llama_parse-0.3.9-py3-none-any.whl (6.8 kB)\n",
            "Collecting rank-bm25<0.3.0,>=0.2.2 (from llama-index-retrievers-bm25==0.1.3->lavague==1.0.4.post1)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium==4.18.1->lavague==1.0.4.post1) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium==4.18.1->lavague==1.0.4.post1)\n",
            "  Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium==4.18.1->lavague==1.0.4.post1)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium==4.18.1->lavague==1.0.4.post1) (2024.2.2)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.12.0->gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.19->lavague==1.0.4.post1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.19->lavague==1.0.4.post1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.19->lavague==1.0.4.post1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.19->lavague==1.0.4.post1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.19->lavague==1.0.4.post1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.19->lavague==1.0.4.post1) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.21.0->lavague==1.0.4.post1) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.21.0->lavague==1.0.4.post1) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.21.0->lavague==1.0.4.post1) (0.12.1)\n",
            "Collecting azure-core<2.0.0,>=1.23.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1) (42.0.5)\n",
            "Collecting msal<2.0.0,>=1.24.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1)\n",
            "  Downloading msal-1.28.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1)\n",
            "  Downloading msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.1.9->lavague==1.0.4.post1) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core==0.10.19->lavague==1.0.4.post1) (1.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.21.0->lavague==1.0.4.post1) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.21.0->lavague==1.0.4.post1) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.21.0->lavague==1.0.4.post1) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.28.0->lavague==1.0.4.post1) (3.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.21.0->lavague==1.0.4.post1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.21.0->lavague==1.0.4.post1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.21.0->lavague==1.0.4.post1) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.21.0->lavague==1.0.4.post1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.21.0->lavague==1.0.4.post1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.21.0->lavague==1.0.4.post1) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.19->lavague==1.0.4.post1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.19->lavague==1.0.4.post1) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.19->lavague==1.0.4.post1) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.19->lavague==1.0.4.post1) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.21.0->lavague==1.0.4.post1) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.21.0->lavague==1.0.4.post1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.21.0->lavague==1.0.4.post1) (2.16.3)\n",
            "Collecting PyMuPDFb==1.24.0 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file==0.1.9->lavague==1.0.4.post1)\n",
            "  Downloading PyMuPDFb-1.24.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results==2.4.2->lavague==1.0.4.post1) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.19->lavague==1.0.4.post1) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface==0.1.4->lavague==1.0.4.post1) (0.15.2)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.18.1->lavague==1.0.4.post1) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium==4.18.1->lavague==1.0.4.post1)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.18.1->lavague==1.0.4.post1) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium==4.18.1->lavague==1.0.4.post1)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.21.0->lavague==1.0.4.post1) (13.7.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium==4.18.1->lavague==1.0.4.post1) (1.7.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.19->lavague==1.0.4.post1)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==4.21.0->lavague==1.0.4.post1)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.23.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->lavague==1.0.4.post1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->lavague==1.0.4.post1) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->lavague==1.0.4.post1) (0.18.0)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal<2.0.0,>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1) (2.3.0)\n",
            "Collecting portalocker<3,>=1.0 (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.21.0->lavague==1.0.4.post1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.21.0->lavague==1.0.4.post1) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.28.0->lavague==1.0.4.post1) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.5->lavague==1.0.4.post1) (2.21)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.21.0->lavague==1.0.4.post1) (0.1.2)\n",
            "Building wheels for collected packages: lavague, google-search-results, ffmpy\n",
            "  Building editable for lavague (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lavague: filename=lavague-1.0.4.post1-0.editable-py3-none-any.whl size=12512 sha256=efce7864de0636b877243aeace7eab29c28a1b7ac05b15d2db0b4a9c50cc77d8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s7yi395a/wheels/25/8a/6e/56ae89e3a1a74aa6622de3f3df0baa59bf111bfc498689ea0c\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=9d80c4f2e5b5144450bd8dc0f77908a3a464e17d491be663f83a7736aa694c32\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=4a8e5b879c61668a10065df5c1a19d43fbf778146d4edf6270d87054244776a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built lavague google-search-results ffmpy\n",
            "Installing collected packages: striprtf, pydub, ffmpy, dirtyjson, websockets, tree-sitter, tomlkit, shellingham, semantic-version, ruff, rank-bm25, python-multipart, python-dotenv, pypdf, PyMuPDFb, portalocker, outcome, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, h11, deprecated, colorama, aiofiles, wsproto, uvicorn, typing-inspect, trio, tree-sitter-languages, tiktoken, starlette, pymupdf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, google-search-results, bs4, bitsandbytes, azure-core, trio-websocket, nvidia-cusolver-cu12, httpx, fastapi, dataclasses-json, selenium, openai, msal, llamaindex-py-client, gradio-client, msal-extensions, llama-index-legacy, llama-index-core, gradio, accelerate, llama-parse, llama-index-retrievers-bm25, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, azure-identity, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-huggingface, llama-index-llms-azure-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-embeddings-azure-openai, llama-index-question-gen-openai, llama-index, lavague\n",
            "Successfully installed PyMuPDFb-1.24.0 accelerate-0.28.0 aiofiles-23.2.1 azure-core-1.30.1 azure-identity-1.15.0 bitsandbytes-0.42.0 bs4-0.0.2 colorama-0.4.6 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 fastapi-0.110.0 ffmpy-0.3.2 google-search-results-2.4.2 gradio-4.21.0 gradio-client-0.12.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 lavague-1.0.4.post1 llama-index-0.10.19 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.9 llama-index-core-0.10.19 llama-index-embeddings-azure-openai-0.1.5 llama-index-embeddings-huggingface-0.1.4 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.4 llama-index-legacy-0.9.48 llama-index-llms-azure-openai-0.1.5 llama-index-llms-huggingface-0.1.4 llama-index-llms-openai-0.1.9 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.9 llama-index-readers-llama-parse-0.1.3 llama-index-retrievers-bm25-0.1.3 llama-parse-0.3.9 llamaindex-py-client-0.1.13 marshmallow-3.21.1 msal-1.28.0 msal-extensions-1.1.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 openai-1.14.2 orjson-3.9.15 outcome-1.3.0.post0 portalocker-2.8.2 pydub-0.25.1 pymupdf-1.24.0 pypdf-4.1.0 python-dotenv-1.0.1 python-multipart-0.0.9 rank-bm25-0.2.2 ruff-0.3.4 selenium-4.18.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 striprtf-0.0.26 tiktoken-0.6.0 tomlkit-0.12.0 tree-sitter-0.21.0 tree-sitter-languages-1.10.2 trio-0.25.0 trio-websocket-0.11.1 typing-inspect-0.9.0 uvicorn-0.29.0 websockets-11.0.3 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lavague-ai/LaVague.git\n",
        "!pip install -e LaVague"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMcF5IjR5FnV"
      },
      "source": [
        "## Running LaVague with OpenAI's GPT3.5\n",
        "\n",
        "### OpenAI API set up\n",
        "\n",
        "Depending on the LLM we want to use, we need to set certain environment variables required for LaVague to work.\n",
        "\n",
        "⚠️ For this demo, we will use LaVague with GPT3.5 via the OpenAI API, so we will need to set our OpenAI key below for this example to work.\n",
        "\n",
        "> If you don't have an OpenAI API key, you can see the OpenAI website for details [on how to create one](https://openai.com/product). Note, that this is a paid service - for a free alternative, see our [HuggingFace API integration](../integrations/hugging-face-api.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hsFCksbV5FnV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x47L29zY5FnV"
      },
      "source": [
        "### LaVague Launch\n",
        "\n",
        "LaVague has two CLI commands `launch` and `build` - let's start by taking a look at the `launch` command which will launch an interactive Gradio where you can perform actions on your desired website.\n",
        "\n",
        "The command we will use to do this is:\n",
        "`lavague-launch --file_path hf.txt --config_path openai.py`\n",
        "\n",
        "- We provide the `file_path` option with a text file containing the URL of the website we want to perform an action on and the natural language instructions for the action(s) we wish to perform.\n",
        "-  We provide the `config_path` option with a Python file which configures LaVague for the specific LLM or set-up we wish to use.\n",
        "\n",
        "We provide default configuration files for key integrations.\n",
        "\n",
        "Let's now download the default config files for OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zcanhcra5FnV",
        "outputId": "9addec5a-032d-4abe-b5e1-5c71ada86f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-25 14:23:20--  https://raw.githubusercontent.com/lavague-ai/LaVague/main/examples/api/openai.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 396 [text/plain]\n",
            "Saving to: ‘openai.py’\n",
            "\n",
            "openai.py           100%[===================>]     396  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-25 14:23:20 (21.8 MB/s) - ‘openai.py’ saved [396/396]\n",
            "\n",
            "--2024-03-25 14:23:20--  https://raw.githubusercontent.com/lavague-ai/LaVague/main/tests/hf.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 188 [text/plain]\n",
            "Saving to: ‘hf.txt’\n",
            "\n",
            "hf.txt              100%[===================>]     188  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-25 14:23:21 (11.5 MB/s) - ‘hf.txt’ saved [188/188]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/lavague-ai/LaVague/main/examples/api/openai.py\n",
        "!wget https://raw.githubusercontent.com/lavague-ai/LaVague/main/tests/hf.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2fkdcTh5FnW"
      },
      "source": [
        "We can inspect the `openai.py` configuration file to see the default values we use by default here.\n",
        "\n",
        "> To learn how these configuration files work and how you can customize them, see our [Customization guide](./customization.md)!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/assets/openai_py.png\"/>\n",
        "\n",
        "We can now launch our interactive Gradio which will be created with three default instructions which can be executed on the HuggingFace website as defined in the `hf.txt` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BudATyn5FnW",
        "outputId": "fd8d9a65-6c8e-4ead-fdc6-53edf12b349f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 743/743 [00:00<00:00, 3.74MB/s]\n",
            "model.safetensors: 100% 133M/133M [00:00<00:00, 161MB/s]\n",
            "tokenizer_config.json: 100% 366/366 [00:00<00:00, 1.81MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 478kB/s]\n",
            "tokenizer.json: 100% 711k/711k [00:00<00:00, 55.0MB/s]\n",
            "special_tokens_map.json: 100% 125/125 [00:00<00:00, 502kB/s]\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://978734f25a4d02d0d3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ],
      "source": [
        "!lavague-launch --file_path hf.txt --config_path openai.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW0WV9DP5FnW"
      },
      "source": [
        "You can now click on the public (if you are using Google Colab) or local URL to open the Gradio in your browser.\n",
        "\n",
        "⚠️ Note, you will need to interact with the generated Gradio demo to perform the desired automated action.\n",
        "\n",
        "First, you should click in the URL textbox and press enter.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/assets/launch_1_openai_py.png\" />\n",
        "\n",
        "Then, you should select your chosen default natural language instruction or write your own, and again click within the instruction textbox and press enter.\n",
        "\n",
        "At this point, Selenium code in Python is generated by the LLM, which is then executed to perform the desired action on the website.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/assets/launch_2_openai_py.png\" />\n",
        "\n",
        "\n",
        "The action will then be visibly executed in the visual interface, but you can also check out the code LaVague generated and executed to perform this action on the right-hand side of the page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO-zMFNE5FnW"
      },
      "source": [
        "### LaVague Build\n",
        "\n",
        "We can alternatively use the `lavague-build` command to generate a Python script with the Selenium code needed to perform the desired action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptwVozUv5FnW"
      },
      "outputs": [],
      "source": [
        "!lavague-build --file_path hf.txt --config_path openai.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9unnssI5FnW"
      },
      "source": [
        "This creates a script in your current directory named `hf_openai.py` - a combination of the two input file names separated by a `_` character.\n",
        "\n",
        "This script contains the Python code using Selenium generated by the LLM to perform the desired action on the URL as specified in your `hf.txt` configuration file.\n",
        "\n",
        "We can now inspect the code and execute it locally!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/assets/build_openai_py.png\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acci_TtT5FnX"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "That brings us to the end of this quick-tour.\n",
        "\n",
        "If you have any further questions, join us on the LaVague Discord [here](https://discord.com/invite/SDxn9KpqX9)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}